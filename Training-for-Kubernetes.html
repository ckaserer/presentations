<!doctype html>
<html>
	<head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-155731101-1"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-155731101-1');
        </script>

		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
        
        <title>Presentation</title>

        <meta name="description" content="Presentation">
        <meta name="author" content="Clemens Kaserer">

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="src/css/general.css" id="theme">
        <link rel="stylesheet" href="src/css/custom.css">
        <link rel="stylesheet" href="src/css/cusotm-code.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>
	<body>

        <!-- Printing and PDF exports -->
        <script>
            var link = document.createElement( 'link' );
            link.rel = 'stylesheet';
            link.type = 'text/css';
            link.href = window.location.search.match( /print-pdf/gi ) ? 'src/css/print/pdf.css' : 'src/css/print/paper.css';
            document.getElementsByTagName( 'head' )[0].appendChild( link );
        </script>

        <!--[if lt IE 9]>
        <script src="lib/js/html5shiv.js"></script>
        <![endif]-->
    </head>
    <body>
        <script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
        
        <!--img src="images/logo.png" style="width: auto; height: 50px; position: fixed; top: 30px; right: 30px; z-index: -9999;" alt="logo"-->
        <!--<p style="font-size:12px !important; z-index:10; color:rgb(0, 0, 0); position: fixed; bottom: 30px; left: calc(50% - 8em);"><i>#BottomBannerText</i></p>-->
		<div class="reveal">
            <div class="slides">
                <section>
    <section>
        <h2>Kubernetes<br>Training</h2>
    </section>

    <section class="no_bg">
        <h2>How We Teach</h2>
        <ul>
            <li>We believe in <b>learning by doing</b></li>
            <li>The training is <b>lab driven</b></li>
            <li>Work together!</li>
            <li>Ask questions at any time</li>
        </ul>       

        <aside class="notes">
            <ul>
                <li>This workshop is primarily exercise based</li>
                <li>Lecture will be limited and focus on the high-level concepts, best practices, and ideas we want to tell you about</li>
                <li>Most of our time will be spent on demo exercises, designed to illustrate the usage, syntax, and details of all the tools we explore, and map onto the learning objectives for each chapter</li>
            </ul>
        </aside>
    </section>
    
    <section class="no_bg">
        <h2>Session Logistics</h2>
        <ul>
            <li>1 day duration</li>
            <li>Mostly exercises</li>
            <li>Regular breaks</li>
        </ul>
    </section>

    <section class="no_bg">
        <h2>Assumed Knowledge and Requirements</h2>
        <ul>
            <li>Familiarity with Docker</li>
            <li>Familiarity with Bash</li>
            <li>Docker Cheat Sheet: <a href="https://bit.ly/3t01s8x">https://bit.ly/3t01s8x</a></li>
            <li>Bash Cheat Sheet: <a href='http://bit.ly/2mTQr8l'>http://bit.ly/2mTQr8l</a></li>
            <!--<li>Powershell Cheat Sheet: <a href='https://bit.ly/2EPHxze'>https://bit.ly/2EPHxze</a></li>-->
        </ul>

        <aside class='notes'>
            <p>Basic familiarity with:</p>
            <ul>
                <li>Filesystem navigation and manipulation: ls, cd, mv, cp, rm</li>
                <li>Tooling: ssh, top, chmod, curl, wget</li>
                <li>Package management with yum</li>
                <li>Building Images, Running Containers, Debugging Containers</li>
                <li>And powershell equivalents</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Your Lab Environment</h2>
        <ul>
            <li>You have been given an instances for use in exercises</li>
            <li>Ask instructor for credentials if you don't have them already</li>
        </ul>

        <aside class='notes'>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Course Learning Objectives</h2>

        <p>By the end of this course, learners will be able to</p>
        <ul>
            <li>Understand the fundamental similarities and differences between docker-compose and Kubernetes</li>
            <li>Utilize Kubernetes orchestrators to deploy, maintain, and scale a distributed application</li>
        </ul>
    </section>  
</section>

<section>
    <section class="no_bg">
        <h2>Introducing Docker</h2>
        <aside class="notes"><h3>An intro module to get students on message with what docker is, and the priorities and concerns of distributed application dev and ops.</h3>
        </aside>
    </section>

    <section class="no_bg">
        <h2>What We Want</h2>

        <p>Ideal software should</p>

        <ul>
            <li>be modular and flexible (devs)</li>
            <li>be easy to migrate (devops)</li>
            <li>be easy to scale, monitor and lifecycle (ops)</li>
            <li>mitigate vulnerabilities (security)</li>
            <li>run cheap (business)</li>
        </ul>

        <aside class='notes'>
            <ul>
                <li>Every stakeholder in the software supply chain has a set of priorities they'd like software to satisfy.</li>
                <li>Developers want flexibility and choice in the components they build application out of; problems like vendor lock-in, technical debt, and tight coupling between components slows the development cycle down and can prevent developers from building the software they want.</li>
                <li>Devops engineers in charge of building and maintaining CI/CD pipelines are primarily responsible for getting applications running across many environments; they'd like to be able to move software easily, and rely that tests passing in one environment won't break in another.</li>
                <li>Operations teams responsible for scaling, maintaining and monitoring software would like to be able to deploy applications easily across a datacenter, and know what to expect from those applications to make monitoring and maintenance simple.</li>
                <li>Security teams want assurances that software not only minimizes attack surfaces, but has built-in failsafes to mitigate compromises when they occur.</li>
                <li>Finally, business interests want to be able to do all of the above as cheaply as possible, by making most efficient use of the compute resources purchased to run it.</li>
                <li>These are many and varied priorities - but containerization is such a success because it speaks to all of them.</li>
            </ul>
        </aside>
    </section>


    <section class="no_bg" style="top: 79.5px; display: block;">
        <h2>Without Containerization</h2>

        <img src='src/modules/Training-for-Containerization/02-docker-story/images/pre-container.png' width="80%"></img>

        <aside class='notes'>
            <ul>
                <li>Without containerization, we can imagine a host that looks as such. The key feature of this diagram is that all the dependencies, configurations, and system resources for applications on this host are shared.</li>
                <li>From the developer's standpoint, an uncontainerized environment requires strict discipline to avoid tight coupling between components; it's easy to develop your way into a state where changes to one component break another, and all components are affected by the environmental requirements of the others, complicating and hindering testing and development.</li>
                <li>For a devops engineer, the shared host environment of these components also adds friction. Every environment in the CI pipeline has to reflect this stack of dependencies and configurations, which can be difficult to maintain and difficult to reproduce.</li>
                <li>For operations personnel, the more tightly coupled different components become, the more difficult they can be to scale and monitor; tight couplings can make it complicated to understand what's needed to relax a performance bottleneck or trace root causes of application failures.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>With Containerization</h2>

        <img src='src/modules/Training-for-Containerization/02-docker-story/images/post-container.png' width="80%"></img>

        <aside class='notes'>
            <ul>
                <li>The fundamental insight of the containerization movement was similar to that of the real-life logistics chains from which containerization got its name: many problems are solved by strictly encapsulating software as we develop, migrate, and deploy it.</li>
                <li>The key feature of a software container is that it is self-contained, all the way down to the OS filesystem; not only our executables, but all their configs and all their dependencies, and even the OS filesystem they run in, are captured in a container that can be moved as a complete unit.</li>
                <li>Modern Linux and Windows kernels can even represent the host system differently to different containers, presenting them different network devices, process trees, filesystems and more; all you need installed on the host is the Docker engine.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Rapid Development</h2>

        <img src='src/modules/Training-for-Containerization/02-docker-story/images/component-upgrade.png'></img>
        <p>Containers can be removed and replaced with a minimum of impact on their neighbors, increasing developer choice and speed.</p>

        <aside class='notes'>
            <ul>
                <li>From the developer's point of view, aggressive encapsulation equals speed and flexibility; since containers provide assurances that one component doesn't affect another, developers can upgrade one component while remaining confident they won't break others.</li>
                <li>Remember that containers carry the full dependency stack of the application they're designed to run, all the way down to the OS filesystem; this means that developers can use different stacks for different components, all on the same host with no chance of dependency conflicts.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Smooth Migration</h2>

        <img src='src/modules/Training-for-Containerization/02-docker-story/images/migration.png'></img>
        <p>Containers carry their environment and dependencies with them, simplifying and minimizing requirements on the hosts that run them.</p>

        <aside class='notes'>
            <ul>
                <li>From the devops point of view, aggressive encapsulation equals smooth migrations; since containers carry everything they need with them, they impose relatively few requirements on the host that runs them. Hosts need only provide a compatible kernel and architecture, and a container engine; no application specific dependencies or environment configurations need be maintained across environments.</li>
                <li>In this way, not only will a container that runs in dev likely run in prod, it will run the same way; containerized software passing tests in one environment has a better chance of passing tests in all environments, since environment matters comparatively little once we containerize our applications.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Simple Scale &amp; Maintenance</h2>

        <img src='src/modules/Training-for-Containerization/02-docker-story/images/scalability.png'></img>
        <p>Weak coupling between containers minimizes side effects when scaling and simplifies monitoring.</p>

        <aside class='notes'>
            <ul>
                <li>From the point of view of operations personnel, the encapsulation provided by containers translates into simple methodology for scaling and maintaining applications.</li>
                <li>Scale is achieved by containers in part by the minimal requirements they put on their environment; since containers are designed to run the same way regardless of their hosting environment, multiple instances can be spun up in parallel, or distributed across all the hosts in a datacenter.</li>
                <li>Furthermore, a well-designed container should run only a very limited set of tasks; by avoiding tight coupling and defining relatively simple behaviors for each container, it becomes simpler to define what 'healthy' means for a container, compared to a complete host with many interacting processes.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Secure by Default</h2>

        <img src='src/modules/Training-for-Containerization/02-docker-story/images/isolation.png'></img>
        <p>Containers have private system resources, so a compromise in one does not affect the rest.</p>

        <aside class='notes'>
            <ul>
                <li>From the point of view of security, aggressive encapsulation automatically enhances our security posture.</li>
                <li>On an uncontainerized host, if an attacker successfully compromises one component with elevated privileges, they can leverage those privileges across the entire host, using any vulnerable component as a point of ingress.</li>
                <li>On the other hand, containerized software mitigates its own vulnerabilities; even if an attacker compromises one container via a vulnerable component, privileges gained there do not grant the same level of access to other containers or to the host; root in a container does not equal root on the host.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Application Density</h2>

        <img src='src/modules/Training-for-Containerization/02-docker-story/images/density.png'></img>
        <p>Containers save datacenter costs by running many more application instances than virtual machines can on the same physical hosts.</p>

        <aside class="notes">
            <ul>
                <li>In terms of operational costs, containers can radically reduce the amount of metal needed to run a given workload compared to a virtual machine, because they are so resource efficient; containerized processes use the host kernel and don't require fixed allocations of CPU and memory, so can be run with the absolute minimal footprint.</li>
                <li>It's not unusual for the same datacenter to be able to run 10x as many containers encapsulating a given process, compared to VMs encapsulating the same software, resulting in substantial cost savings to users.</li>
            </ul>
        </aside>
    </section>

    <!--
    <section class="no_bg">
        <h2>The Containerization Stack</h2>

        <div style='text-align:center !important'>
            <img style='width:60%' src='src/modules/Training-for-Containerization/02-docker-story/images/container-stack.png'></img>
        </div>

        <aside class='notes'>
            <ul>
                <li>Any containerization stack needs three elements:</li>
                <li>A container runtime to actually make containers</li>
                <li>An orchestration layer to network containers together, potentially across remote hosts</li>
                <li>An enterprise tooling layer that provides for the management and security needs of large enterprises.</li>
                <li>Docker Community Edition provides the container runtime, and an orchestrator (based on SwarmKit), free for anyone to use. Kubernetes is also available as an alternative, powerful orchestration layer.</li>
                <li>Docker Enterprise Edition goes beyond the free product to provide tools like a secure API, role based access control, and tooling for creating container-based CI/CD pipelines.</li>
                <li>In this course, we're going to study the first two layers of the containerization stack; join us for our more advanced courses that dive into our enterprise tooling.</li>
            </ul>
        </aside>
    </section>
    -->
</section>
<section>
    <section class="no_bg">
        <h2>Introduction to Docker Compose</h2>
        <aside class="notes">
            <ul>
                <li>Docker provides a number of fundamental tools for approaching the problem of orchestration natively from Docker, and the first of these tools is Compose.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Discussion: Processes vs. Applications</h2>

        <p>Containers and images describe individual processes. What will we need to describe entire applications?</p>

        <aside class='notes'>
            <ul>
                <li>Lead class to the simple answer (some sort of manifest file that describes the application, in the spirit of deploy scripts or infrastructure-as-code), as well as the more substantial answer of some way to manage a living application, where 'manage' in this context means scale, route traffic, deploy and upgrade.</li>
                <li>Hint questions if the class is stuck:</li>
                <li>It's not enough just to 'describe' an application - we need to make the deployment of those applications reproducible and portable. How? (someone should think of some sort of script).</li>
                <li>Are applications static after they're launched? What if load changes? (leads to thinking about scaling).</li>
                <li>After scaling an application, how do we make sure traffic gets to the new instances of our app? Re-do service discovery? Reconfigure load balancers? We'd rather have something a little more transparent.</li>
            </ul>
        </aside>

    </section>

    <section class="no_bg">
        <h2>Learning Objectives</h2>

        <p>By the end of this module, learners will be able to</p>
        <ul>
            <li>Design scalable Docker services</li>
            <li>Leverage Docker's built in service discovery mechanism</li> 
            <li>Write a compose file describing an application</li>
        </ul>

    </section>

    <section class="no_bg">
        <h2>Distributed Application Architecture</h2>

        <ul>
            <li>Applications consisting of one or more containers across one or more nodes</li>
            <li>Docker Compose facilitates multi-container design <span class='keyword'>on a single node</span></li>
        </ul>

        <aside class="notes">
            <ul>
                <li>At this point, we've seen that Docker can provide adequately portable and isolated containers, and we've seen some basic nuts and bolts regarding how those containers can be networked together; we're now ready to start exploring our first orchestration tool for making a true distributed application.</li>
                <li>Ultimately, we'll want to be able to completely decentralize our application, be networking many containers together across many hosts; for now, we'll just solve half the problem, by making an application out of many containers, still all on the same host. We'll relax the single-host constraint in the next chapter.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Docker Services</h2>

            <ul>
                <li>Goal: declare and (re)configure many similar containers all at once</li>
                <li>Goal: scale apps by adding containers seamlessly</li>
                <li>A <span class='keyword'>service</span> defines the <span class='keyword'>desired state</span> of a group of identically configured containers</li>
                <li>Docker provides <span class='keyword'>transparent service discovery</span> for Services</li>
            </ul>

            <aside class='notes'>
                <ul>
                    <li>So far, we've declared containers one at a time with `docker container run...`, and we've seen how to network individual containers together. This all works, but doesn't scale conveniently.</li>
                    <li>Since we're going to start designing apps to consist of potentially many containers, we'd like to be able to create and reconfigure containers en masse.</li>
                    <li>Furthermore, we need to put some thought into how discovery will work in this paradigm; if we scale up an app by declaring more containers, how will they all find out about each other and network themselves together</li>
                    <li>To address this problem, Docker orchestration introduces the idea of services. A service defines the desired state of a collection of identically configured containers, allowing us to declare a batch of containers all at once, and reconfigure them later by updating the service definition.</li>
                    <li>Furthermore, Docker provides out-of-the-box service discovery for services, automatically providing and configuring the networking necessary for these groups of containers to interact.</li>
                </ul>
            </aside>
    </section>  

    <section class="no_bg">
        <h2>Service Discovery</h2>

        <img src='src/modules/Training-for-Kubernetes/03-compose/images/service-not-process.png' style='width:90%'></img>
        <p>Services are assigned a <span class='keyword'>Virtual IP</span> which spreads traffic out across the underlying containers automatically.</p>

        <aside class='notes'>
            <ul>
                <li>Formerly, we may have had individual processes or containers communicating directly; this isn't practical for a service we want to scale into many processes on demand.</li>
                <li>To address this, Docker assigns a virtual IP to every service, and maintains a DNS lookup table on the host, so that at the application logic level, traffic can be directed to a service as a whole; load balancing to the underlying containers is handled by Docker's onboard VIP server.</li>
                <li>In this way, we can change the number of containers provisioned by a service without needing to do any explicit service discovery in our applications; the application logic sends traffic to the service regardless of how many containers it has provisioned, and Docker does the rest.</li>
            </ul>
        </aside>
    </section>    

    <section class="no_bg">
        <h2>Our Application: Dockercoins</h2>

        <div class='col-6'>
            <img style="background-color:rgba(0,0,0,0); max-width:80%;" src="src/modules/Training-for-Kubernetes/03-compose/images/dockercoins.png" alt="DockerCoins logo" />
            <p style='font-size: medium !important'>
                (DockerCoins 2016 logo courtesy of <a href="https://twitter.com/xtlcnslt">@XtlCnslt</a> and <a href="https://twitter.com/ndeloof">@ndeloof</a>. Thanks!)
            </p>
        </div>

        <div class='col-6'>
            <ul>
                <li>
                    It is a DockerCoin miner! 💰🐳📦🚢
                </li>
                <li>
                    Dockercoins consists of 5 services working together:
                </li>
            </ul>
            <img src='src/modules/Training-for-Kubernetes/03-compose/images/dockercoins-flow.png' style='width:70%'></img>
        </div>
    </section>

    <section data-background="#340B65" class="green_bg">
        <h2><img src="src/modules/Training-for-Kubernetes/03-compose/images/icon_task.png" class="moby_icon" alt="icon"> Instructor Demo: Docker Compose</h2>

        <p>See the demo</p> 
        
        <ul>
            <li class='demo' script='docker-compose-demo.md'>Docker Compose</li>
        </ul>

        <p>In the Exercises book.</p>
    </section>

    <section data-background="#00a2a1" class="green_bg">
        <h2><img src="src/modules/Training-for-Kubernetes/03-compose/images/icon_task.png" class="moby_icon" alt="icon"> Exercise: Compose Apps</h2>
        <p>Work through</p>
        <ul>
            <li class='exercise' script='starting-a-compose-app.md'>Starting a Compose App</li>
            <li class='exercise' script='scaling-a-compose-app.md'>Scaling a Compose App</li>
        </ul>

        <p>in the Exercises book.</p>
        <h2 class="timer"></h2>
    </section> 

    <section class="no_bg">
        <h2>Docker Compose Takeaways</h2>

        <ul>
            <li>Docker Compose makes single node orchestration easy</li>
            <li>Compose services makes scaling applications easy</li>
            <li>Bottleneck identification important</li>
            <li>Syntactically: <code>docker-compose.yml</code> + API</li>
        </ul>

        <aside class='notes'>
            <ul>
                <li>Compose should be your go-to native Docker solution for orchestrating services and containers on a single node.</li>
                <li>In the next section, we'll learn how to do the same across many nodes.</li>
            </ul>
        </aside>

    </section>

    <section class="no_bg">
        <h2>Further Reading</h2>

        <ul>
            <li>Docker compose examples: <a href="http://dockr.ly/1FL2VQ6">http://dockr.ly/1FL2VQ6</a></li>
            <li>Overview of docker-compose CLI: <a href="http://dockr.ly/2wtQlZT">http://dockr.ly/2wtQlZT</a></li>
            <li><code>docker-compose.yaml</code> reference: <a href="http://dockr.ly/2iHUpeX">http://dockr.ly/2iHUpeX</a></li>
            <li>Docker Compose and Windows: <a href="http://bit.ly/2watrqk">http://bit.ly/2watrqk</a></li>
        </ul>

        <aside class='notes'>
            <ul>
                <li>additional resources about Docker compose</li>
            </ul>
            
        </aside>
    </section>
</section><section>
    <section class="no_bg">
        <h2>Wrap Up Docker-Compose - Sonarqube</h2>
    </section>
    <section class="no_bg">
        <h2>Sonarqube</h2>
        <img src='src/modules/Training-for-Kubernetes/04-wrapup-compose/images/sonarqube.png' style='height: 400px' class="transparent"></img>
    </section>
    <section data-background="#00a2a1" class="green_bg">
        <h2>Exercise Instructions</h2>
        <ul>
            <li>Setup a Sonarqube server that listens on port 9000</li>
            <li>Connect it to a persistent database<br>i.e. if you ‚docker rm –f‘ your Sonarqube container and run a new one, no data is lost</li>
            <li>Use postgresql and persist it‘s data on the host filesystem using volumes</li>
            <li>Verify e.g. by creating a user via Sonarqube UI, remove the container and run a new one – is the user still present?</li>
            <li>Check that Sonarqube is really using your postgresql database
            </li>
            <li><b>Hint</b>: use docker-compose</li>
        </ul>
        <br>
        <br>
        <h2 class="timer"></h2>
        <aside class="notes">
            Check that Sonarqube is really using your postgresql database: 
                <ul>
                    <li>login to postgres container</li>
                    <li>psql sonar sonar</li>
                    <li>\l - list all existing databases</li>
                    <li>\dt - list all tables of databases</li>
                    <li><b>Hint</b>: Postgresql tips at http://www.unixwitch.de/de/sysadmin/tools/postgres</li>
                </ul>
        </aside>
    </section>
    
    <section class="no_bg">
        <h2>Solution</h2>
        <div class='pre' style="font-size:small;">version: "2"
services:
  sonarqube:
    image: sonarqube
    ports:
      - "9000:9000"
    networks:
      - sonarnet
    environment:
      - SONARQUBE_JDBC_URL=jdbc:postgresql://db:5432/sonar
    volumes:
      - sonarqube_conf:/opt/sonarqube/conf
      - sonarqube_data:/opt/sonarqube/data
      - sonarqube_extensions:/opt/sonarqube/extensions
      - sonarqube_bundled-plugins:/opt/sonarqube/lib/bundled-plugins

  db:
    image: postgres
    networks:
      - sonarnet
    environment:
      - POSTGRES_USER=sonar
      - POSTGRES_PASSWORD=sonar
    volumes:
      - postgresql:/var/lib/postgresql
      - postgresql_data:/var/lib/postgresql/datanetworks:
    sonarnet:
      driver: bridge

volumes:
  sonarqube_conf:
  sonarqube_data:
  sonarqube_extensions:
  sonarqube_bundled-plugins:
  postgresql:
  postgresql_data:</div>

    </section>
</section><section>
    <section class="no_bg">
        <h2>Introduction to Kubernetes</h2>
    </section>

    <section class="no_bg">
        <h2>Discussion: Any App, Anywhere?</h2>

        <p>Containers are portable. What does this imply about the best ways to manage a containerized data center?</p>

        <aside class='notes'>
            <ul>
                <li>Lead class to consider the advantage of letting containers get scheduled anywhere, rather than controlling exactly where they get scheduled. Then, explore what the consequences of what spreading containers across multiple hosts are (need for management, control and data planes; need for some special-case control over scheduling decisions).</li>
                <li>Hint questions if the class is stuck:</li>
                <li>In general, does it matter where a given container gets scheduled? Why or why not? (conclude that in most cases, it doesn't matter, but there may be special cases such as needing specific hardware, or being sensitive to resource availability).</li>
                <li>If we're scheduling containers on any arbitrary host in our datacenter, we're going to need some sort of cluster manager in order to administrate all these hosts and containers. How will we provide service discovery? (Consider things like peer-to-peer service discovery (no choke points but could generate a lot of traffic), hub and spoke distribution (potentially less traffic but single points of failure), lookup from a kv store (just-in-time lookup could minimize traffic but might block traffic depending on implementation). Others?)</li>
                <li>Once we've solved the service discovery problem, how are we going to get packets from one host to another? Recall that so far, we've only seen linux bridges moving packets around at layer 2.</li>
                <li>Enabling this full-datacenter scheduling and solving the corresponding and communication challenges are the fundamental responsibilities of any production-ready container orchestrator.</li>
            </ul>
        </aside>
    </section>
    
    <!--
    <section class="no_bg">
        <h2>Discussion: Container Communication</h2>

        <p>Suppose you have two services you want to guarantee can reach each other on the same host, to eliminate network latency. How would you do this in Swarm?</p>

        <aside class='notes'>
            <ul>
                <li>Concrete example: an API tier that needs to hit a database tier - don't want to wait for network latency between the two.</li>
                <li>Entertain suggestions from the class for a while until concluding that there's no way to do this with swarm services. Kubernetes solves the same fundamental problems as any orchestrator, but gives an alternative networking and scheduling model that supports different use cases than Swarm.</li>
            </ul>
        </aside>

    </section>
    -->

    <section class="no_bg">
        <h2>Learning Objectives</h2>
        
        <p>By the end of this module, learners will be able to</p>

        <ul>
            <li>Understand the components and roles of Kubernetes masters and nodes</li>
            <li>Identify and explain the core Kubernetes objects (Pod, ReplicaSet, Deployment, Service, Volumes)</li>
            <li>Provision configuration via configMaps and secrets</li>
            <li>Explore the Kubernetes networking model</li>
        </ul>
    </section> 

    <section class="no_bg">
        <h2>Orchestrator Goals</h2>

        <p><span class='keyword'>Top-line goal:</span> operate a datacenter like a <span class='keyword'>pool of compute resources</span> (not individual machines). This requires</p>

        <ul>
            <li>Add / remove compute resources securely and easily</li>
            <li>Schedule containers across the cluster transparently</li>
            <li>Streamline container-to-container communication (service discovery, load balancing and routing)</li>
        </ul>

        <aside class='notes'>
            <ul>
                <li>The core goal of any orchestrator is to let you treat a bunch of computers like a pool of compute resources ready to support your containerized workloads; the fact that containers are so portable and work the same way anywhere means we generally don't have to care too much what specific node they get scheduled on. Instead, we'd like to delegate that decision to our orchestrator, and think about our cluster as a whole rather than as a lot of individual machines.</li>
                <li>In order to actually do that, there are some minimal requirements any orchestrator will need to satisfy:</li>
                <li>Not only do we have to be able to add new nodes to our cluster, this has to be done in a way that is secure at join time, and secure in communication long term.</li>
                <li>Our orchestrator will need to be able to schedule workload anywhere in the cluster; this is perhaps the easiest part, thanks to the portability of containers. Beyond this, our orchestrator should also be responsible for automatically maintaining that workload as much as possible.</li>
                <li>Finally, with our applications potentially divided among many containers and hosts, we'll need our orchestrator to help us communicate between these containers, by facilitating service discovery, load balancing and routing appropriate to the networking needs of each of our applications.</li>
                <li>There are of course many more things an orchestrator could do for us, but these are the core concerns that any feasible orchestrator must do.</li>
            </ul>
        </aside>
    </section>
    <section class="no_bg">
        <h2>Pets Versus Livestock</h2>

        <div class='row'>
            <div class='col-4'>
                <ul>
                    <li>Kubernetes reschedules exited containers automatically</li>
                    <li style='margin-right:1em'>When a container becomes unhealthy, <span class='keyword'>kill it and get a new one</span>.</li>
                </ul>
            </div>
            <div class='col-8'>
                <img src='src/modules/Training-for-Kubernetes/05-kubernetes-basics/images/petsvslivestock.png' style="background:none !important;">
                 <figcaption style="font-size:50%; line-height:0; text-align:center; margin-top: 1em;">Dog photo <a href="https://www.flickr.com/photos/jeffreyww/4975374886/in/photolist-8zE6BC-c9tWCb-c9tXfd-5a7MyF-c3KLuL-5dDirY-axQTra-c9sgSG-amLcYQ-c3KFn7-c9tXo1-c9tWc9-dHZUz-rgAhXo-rW2iU1-KSM6e-pSCtLH-qF7ff3-5Sqz9E-fmSgbs-7KxKak-8TZKk8-6gVmH9-ehfejV-ehtrx4-bD41t2-aiMDUn-8U3iS9-DacH2L-63pHfi-8TZfEH-93nazZ-dmdgPv-85pGjL-8p9Un7-8p9Ui3-5a7EUt-8qP6BK-345kg4-8BRoqc-65p6Gq-YkNMy4-8J4rLP-o2EFGs-H43vF2-8U3jm3-8U48Fb-Si8zjf-8U48pY-2dBGh2">jeffreyw</a>; Livestock photo <a href="https://www.flickr.com/photos/pauljill/28350728097/in/photolist-KcfTJR-a38m8q-tNhS3j-27TRuXP-Ssmqi7-9uD1Xw-PyTy8A-4D77Jm-8pSu5Q-W3FcwF-ZypKkz-Ue3XvX-VP9jfs-28pSeWb-UP2ryi-LQt3rp-UT391d-MEqR17-Y7sweh-8X7vrU-Y7FJfm-QBydX8-FgTo81-XZr5cN-SPXUwJ-rhVK-bmDYEB-dPFa64-287ET1L-UZyj2p-TcrWzo-ZzPMvn-8JAYv1-48S7W5-8C3qEJ-J6FjAR-urgqiC-f4E4kU-DTLaj9-24prtP3-6P3yWW-28ynA9Q-UPjBk8-UyDxAW-XwKZRW-24HpVUY-ehvBKf-HbXbmw-BSCQ2s-8Uz7pW"> Paul Asman, Jill Lenoble</a>; images <a href='https://creativecommons.org/licenses/by/2.0/'>CC-BY 2.0</a></figcaption>
            </div>
        </div>

        <aside class='notes'>
            <ul>
                <li>In the exercises and demos so far, we've seen how Swarm will reschedule containers after they exit. This is a crucial feature for how we think about managing orchestrated container workloads.</li>
                <li>We often describe this mindset as livestock management, versus pet care. With a pet, we concern ourselves with every injury and illness, and attempt to keep our pet healthy and happy as long as possible; this is the wrong way to think about troubleshooting containers. As any rancher knows, what matters is not the health of an individual livestock animal, but the health of the herd. If one animal gets sick, the right course of action is to kill it and get a new one. The same is true with containers; if a container scheduled by swarm misbehaves, the first course of action to take is to kill it and let Swarm reschedule it.</li>
                <li>If pathologies persist after rescheduling fresh containers, then a more serious debugging effort makes sense - but not when a single container gets rescheduled or has to be restarted.</li>
                <li>Bear in mind this is usually a big change from how we thought about managing VMs - VMs were more like pets we want to keep alive. Bringing the same management and troubleshooting mindset to the containerization world is a common mistake that causes new container users a lot of unnecessary pain.</li>
            </ul>
        </aside>
    </section> 

    <section class="no_bg">
        <h2>Kubernetes Master</h2>
        <div class="row">
            <div class="col-7">
                <p>Important Components</p>
                <ul>
                    <li><span class="keyword">API Server:</span> Frontend into Kubernetes control plane</li>
                    <li><span class="keyword">Cluster Store:</span> Config and state of cluster</li>
                    <li><span class="keyword">Controller Manager:</span> Assert desired state</li>
                    <li><span class="keyword">Scheduler:</span> Assigns workload to nodes</li>
                </ul>
            </div>
            <div class="col-5">
                <img src="src/modules/Training-for-Kubernetes/05-kubernetes-basics/images/master.png" title="master" style="margin-left: 20px;">
            </div>
        </div>
        <aside class="notes">
            <ul>
                <li>The API Server (apiserver) is the frontend into the Kubernetes control plane. It exposes a RESTful API that preferentially consumes JSON. We POST manifest files to it, these get validated, and the work they define gets deployed to the cluster.</li>
                <li>The config and state of the cluster gets persistently stored in the cluster store, which is the only stateful component of the cluster and is vital to its operation - no cluster store, no cluster!<br> The cluster store is based on etcd, the popular distributed, consistent and watchable key-value store. As it is the single source of truth for the cluster, you should take care to protect it and provide adequate ways to recover it if things go wrong.</li>
                <li>The controller manager (kube-controller-manager) implements things like the node controller, endpoints controller, namespace controller etc. They tend to sit in loops and watch for changes – the aim of the game is to make sure the current state of the cluster matches the desired state</li>
                <li>At a high level, the scheduler (kube-scheduler) watches for new workloads and assigns them to nodes. Behind the scenes, it does a lot of related tasks such as evaluating affinity and anti-affinity, constraints, and resource management.</li>
                <li>Note that directly analogous components appear in a Swarm manager; in Swarm's case they are integrated directly into the Docker engine, but the same roles and responsibilities appear in both. This is the first example of what we meant by Kube being more modularly designed.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Kubernetes Node</h2>
        <div class="row">
            <div class="col-7">
                <ul>
                    <li><span class="keyword">Kubelet:</span> Kubernetes Agent</li>
                    <li><span class="keyword">Container Engine:</span> Host Containers</li>
                    <li><span class="keyword">Network Proxy:</span> Networking &amp; Load Balancing</li>
                </ul>
            </div>
            <div class="col-5">
                <img src="src/modules/Training-for-Kubernetes/05-kubernetes-basics/images/node.png" title="master" style="margin-left: 20px;">
            </div>
        </div>
        <aside class="notes">
            <ul>
                <li>Kubelet: This is the main Kubernetes agent that runs on all cluster nodes. When kubelet is installed on a Linux host then it registers the host with the cluster as a node. It then watches the API server for new work assignments. Any time it sees one, it carries out the task and maintains a reporting channel back to the master.</li>
                <li>If the kubelet can’t run a particular work task, it reports back to the master and lets the control plane decide what actions to take. For example, if a Pod fails on a node, the kubelet is not responsible for restarting it or finding another node to run it on. It simply reports back to the master. The master then decides what to do.</li>
                <li>Container Engine: The Kubelet needs to work with a container runtime to do all the container management stuff – things like pulling images and starting and stopping containers. More often than not, the container runtime that Kubernetes uses is Docker. In the case of Docker, Kubernetes talks natively to the Docker Remote API.</li>
                <li>More recently, Kubernetes has released the Container Runtime Interface (CRI). This is an abstraction layer for external (3rd-party) container runtimes to plug in to. Basically, the CRI masks the internal machinery of Kubernetes and exposes a clean documented container runtime interface. The CRI is now the default method for container runtimes to plug-in to Kubernetes. The containerd CRI project is a community-based open-source project porting the CNCF containerd runtime to the CRI interface.</li>
                <li>Kube Proxy: The last piece of the puzzle is the kube-proxy. This is like the network brains of the node. For one thing, it makes sure that every Pod gets its own unique IP address. It also does lightweight load-balancing on the node.</li>
            </ul>
        </aside>
    </section>
        
    <section class="no_bg">
        <h2>Architecture</h2>
        <img src="src/modules/Training-for-Kubernetes/05-kubernetes-basics/images/architecture.png" title="Architecture">
        <aside class="notes">
            <ul>
                <li>In this schema we have one master and 3 nodes. On the master we find the 4 services that we discussed earlier: API service, scheduler, controller manager and cluster storage</li>
                <li>On each of the nodes we have kubelet, Kubernetes proxy and the container host such as containerd. The container host runs containers C1, ..., Cx</li>
            </ul>
        </aside>
    </section>

    <section data-background="#340B65" class="green_bg">
        <h2><img src="src/modules/Training-for-Kubernetes/05-kubernetes-basics/images/icon_task.png" class="moby_icon" alt="icon">Instructor Demo: Kubernetes Basics</h2>
        
        <p>See the demo</p> 
        
        <ul>
            <li class='demo' script='kubernetes-demo.md'>Kubernetes Basics</li>
        </ul>

        <p>In the Exercises book.</p>
    </section> 

    
    <section data-background="#00a2a1" class="green_bg">
        <h2><img src="src/modules/Training-for-Kubernetes/05-kubernetes-basics/images/icon_task.png" class="moby_icon" alt="icon"> Exercise: Installing Kubernetes</h2>
        
        <p>Work through</p>

        <ul>
            <li class='exercise' script='kube-install.md'>Installing Kubernetes</li>
        </ul>

        <p>in the Exercises book.</p>
        <h2 class="timer"></h2>

    </section>

    <section class="no_bg">
        <h2>Further Reading</h2>
        <ul>
            <li>Docker &amp; Kubernetes: <a href="https://www.docker.com/kubernetes">https://www.docker.com/kubernetes</a></li>
            <li>Official Kubernetes Docs: <a href="https://kubernetes.io/docs">https://kubernetes.io/docs</a></li>
            <li>Tutorials: <a href="http://bit.ly/2yLGn61">http://bit.ly/2yLGn61</a></li>
            <li>Interactive Tutorials: <a href="https://bit.ly/2rdwIVZ">https://bit.ly/2rdwIVZ</a></li>
            <li>Understanding Kubernetes Networking: <a href="http://bit.ly/2kdI1qQ">http://bit.ly/2kdI1qQ</a></li>
            <li>Kubernetes the Hard Way: <a href="http://bit.ly/29Dq4wC">http://bit.ly/29Dq4wC</a></li>
        </ul>
        <aside class='notes'>
            <ul>
                <li>Additional resources about Kubernetes</li>
            </ul>
        </aside>
    </section>
</section>
<section>
    <section class="no_bg">
        <h2>Kubernetes Ressources</h2>
    </section>

    <section class="no_bg">
        <h2>Kubernetes Orchestration Objects</h2>

        <img src="src/modules/Training-for-Kubernetes/06-kubernetes-ressources/images/deployment.png" title="Deployment">

        <aside class='notes'>
            <ul>
                <li>While Docker Swarm provides a complete orchestration stack in its service objects, Kubernetes defines several different entities that must be combined to achieve the same result. This is the other way in which kubernetes is more modular than swarm, in that its orchestration abstractions are broken down into multiple objects.</li>
                <li>Pod: In Kubernetes a Pod is the atomic unit of scheduling. We cannot run containers directly on a Kubernetes cluster.</li>
                <li>At the highest-level, a Pod is a ring-fenced environment to run containers. The Pod itself doesn’t actually run anything, it's just a sandbox to run containers in. Keeping it high level, we ring-fence an area of the host OS, build a network stack, create a bunch of kernel namespaces, and run one or more containers in it.</li>
                <li>If one runs multiple containers in a Pod, they all share the same environment - things like the IPC namespace, shared memory, volumes, network stack etc. As an example, this means that all containers in the same Pod will share the same IP address (the Pod’s IP).</li>
                <li>ReplicaSet: A ReplicaSet is a higher-level Kubernetes object that wraps around a Pod and adds features. As the names suggests, they take a Pod template and deploy a desired number of replicas of it. They also instantiate a background reconciliation loop that checks to make sure the right number of replicas are always running – desired state vs actual state. ReplicaSets can be deployed directly. But more often than not, they are deployed indirectly via even higher-level objects such as Deployments.</li>
                <li>Deployment: Deployments provide broader desired state management to ReplicaSets. After updating the declarative desired state of replicasets in the JSON or YAML that describes a Deployment, those updates will be rolled out in a controlled fashion (ie a rolling update).</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Pods</h2>

        <img src="src/modules/Training-for-Kubernetes/06-kubernetes-ressources/images/podstructure.png" title="Pods" style='max-width:50%'>
        <p><span class='keyword'>Logical host</span> supporting interacting processes</p>

        <aside class='notes'>
            <ul>
                <li>Perhaps the most fundamental conceptual difference between Docker and Kubernetes is the notion of a pod. While Docker's fundamental scheduling unit is a container - a single process with the full stack of isolation technologies applied to it - kubernetes's atomic unit is the pod, which is meant to model a logical host supporting multiple interacting processes.</li>
                <li>At the kernel namespace level, pods reduce some of the isolation between containers by sharing their network, IPC, and UTS namespaces. This allows all the containers within a pod to interact with each other as if they were all sitting on the same host.</li>
                <li>As such, all the containers within a pod share a single IP address, port range, routing table, hostname, and unix sockets. This is the first example of what we meant by kubernetes prioritizing its communication model over its security model.</li>
                <li>Resource limitations by way of control groups are imposed at the pod level; security features like capabilities management, SecComp and security modules are bundled together as securityContext objects (container context takes precedence over pod context).</li>
                <li>All pods contain something called a pause container, which is responsible for keeping the shared namespaces of the pod open even if all other processes in the pod exit or restart.</li>
            </ul>
        </aside>

    </section>    

    <section class="no_bg">
        <h2>Pods</h2>
        <div class="row">
            <div class="col-7">
                <img src="src/modules/Training-for-Kubernetes/06-kubernetes-ressources/images/pod-addr.png" title="Pods">
            </div>
            <div class="col-5">
                <ul>
                    <li>Use <code>localhost</code> for intra-pod communication</li>
                    <li>All containers in a pod share same IP</li>
                </ul>
            </div>
        </div>
        <aside class="notes">
            <ul>
                <li>Since all containers in a pod share the same network namespace and they all pertain to the same (pod) IP address, containers can just communicate with each other via "localhost".</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Pod Networking</h2>
        <img src="src/modules/Training-for-Kubernetes/06-kubernetes-ressources/images/docker-vs-k8s.png" title="Pod Networking">
        <aside class="notes">
            <ul>
                <li>The Docker network:</li>
                <li>On top we have a physical network interface called "eth0". Attached to that is a Linux bridge "docker0", and attached to that is a virtual network interface "veth0". It is important to note that "docker0" and "veth0" are both on the same network, 172.5.0.0/24 in this example. On this network "docker0" is assigned the IP address 172.5.0.1 and it is the default gateway for "veth0", which is assigned the IP address 172.5.0.2.</li>
                <li>The second container gets a new virtual network interface "veth1", connected to the same "docker0" bridge. In our case it is assigned the IP address 172.5.0.3</li>

                <li>Kubernetes Network:</li>
                <li>Docker can start a container and rather than creating a new virtual network interface for it, specify that it shares an existing interface.</li>
                <li>The command looks like this: "docker container run --name bar ... --net container:foo ..."</li>
                <li>The above command shares the network namespace of container "foo" with the new container "bar".</li>
                <li>Now the second container "bar" sees "veth0" rather than getting its own "veth1" as in the previous example.</li>
                <li>In this way multiple containers live in the same network space and can communicate with each other via `localhost`. This is similar to what we know from the situation when we run multiple processes directly on the host.</li>
                <li>Kubernetes implements this pattern by creating a special container "pause" for each pod whose only purpose is to provide a network interface for the other containers.</li>
                <li>The “pause” container is the heart of the pod, providing the virtual network interface that all the other containers will use to communicate with each other and the outside world.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Pod Lifecycle</h2>

        <img src="src/modules/Training-for-Kubernetes/06-kubernetes-ressources/images/pod-lifecycle.png" title="Pod Lifecycle">

        <aside class="notes">
            <ul>
                <li>A pod has a lifecycle. Since a it is also an atomic unit of deployment the following is valid:</li>
                <li>Pending: containers are still spinning up (ie being scheduled by kube, and images being downloaded if necessary).</li>
                <li>Running: pod is bound to a node, and at least one container is still running or restarting.</li>
                <li>Succeeded: all containers exited with exit code 0</li>
                <li>Failed: all containers exited, at least one with a non-zero exit code.</li>
                <li>Note the monotonous progression: unlike containers, pods don't stop and restart. They live until they die.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>ReplicaSet</h2>

        <div class="row">
            <div class="col-8">
                <img src="src/modules/Training-for-Kubernetes/06-kubernetes-ressources/images/replicaset.png" title="ReplicaSet">
            </div>
            <div class="col-4">
                <ul>
                    <li>Scaling</li>
                    <li>Keep-alive</li>
                </ul>
            </div>
        </div>

        <aside class="notes">
            <ul>
                <li>ReplicaSets bring the concepts of desired number of replicas and self-healing to a collection of Pods. Just like in Swarm when a service task dies, a dead pod will be rescheduled by a ReplicaSet.</li>
                <li>We define ReplicaSets with either a YAML or a JSON manifest file and feed it to the API server. This gets handed over to the ReplicaSet controller which makes sure the right number of the right Pod get instantiated. Fundamental to this is the all-powerful reconciliation loop that is constantly watching the cluster and making sure that current state and desired state match.</li>
                <li>Even if we only need a single instance of a Pod, we should probably deploy it via a higher-level object like a ReplicaSet or Deployment. This will give the Pod self-healing capabilities and the ability to scale if we decide we need more in the future.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Deployment</h2>
        <div class="row">
            <div class="col-6">
                <img src="src/modules/Training-for-Kubernetes/06-kubernetes-ressources/images/deployment.png" title="Deployment">
            </div>
            <div class="col-6">
                <ul>
                    <li>Build on top of <span class="keyword">ReplicaSets</span></li>
                    <li>Add configurable Updates and Rollback</li>
                    <li>Older Versions of ReplicaSets stick around for easy Rollback</li>
                </ul>
            </div>
        </div>
        <aside class="notes">
            <ul>
                <li>Deployments build on top of Pods and ReplicaSets by adding mature and configurable updates and rollbacks.</li>
                <li>Like everything else, they’re objects in the Kubernetes API and we should be looking to work with them declaratively.</li>
                <li>When we perform updates with the kubectl apply command, older versions of ReplicaSets get wound down, but they stick around making it easy for us to perform rollbacks.</li>
            </ul>
        </aside>
    </section>
    
    <section data-background="#00a2a1" class="green_bg">
        <h2><img src="src/modules/Training-for-Kubernetes/06-kubernetes-ressources/images/icon_task.png" class="moby_icon" alt="icon"> Exercise: Kubernetes Orchestration</h2>
        
        <p>Work through</p>

        <ul>
            <li class='exercise' script='kube-orchestration.md'>Kubernetes Orchestration</li>
        </ul>

        <p>in the Exercises book.</p>
        <h2 class="timer"></h2>

    </section>

    
    <section class="no_bg">
        <h2>Further Reading</h2>
        <ul>
            <li>Docker &amp; Kubernetes: <a href="https://www.docker.com/kubernetes">https://www.docker.com/kubernetes</a></li>
            <li>Official Kubernetes Docs: <a href="https://kubernetes.io/docs">https://kubernetes.io/docs</a></li>
            <li>Tutorials: <a href="http://bit.ly/2yLGn61">http://bit.ly/2yLGn61</a></li>
            <li>Interactive Tutorials: <a href="https://bit.ly/2rdwIVZ">https://bit.ly/2rdwIVZ</a></li>
            <li>Understanding Kubernetes Networking: <a href="http://bit.ly/2kdI1qQ">http://bit.ly/2kdI1qQ</a></li>
            <li>Kubernetes the Hard Way: <a href="http://bit.ly/29Dq4wC">http://bit.ly/29Dq4wC</a></li>
        </ul>
        <aside class='notes'>
            <ul>
                <li>Additional resources about Kubernetes</li>
            </ul>
        </aside>
    </section>
</section>
<section>
    <section class="no_bg">
        <h2>Configuration & Secrets</h2>
    </section>

    <section class="no_bg">
        <h2>Configuration</h2>

        <p>Applications typically need environment-specific config:</p>
        <ul>
            <li>Environment variables</li>
            <li>Configuration files</li>
            <li>Non-sensitive info (ports, usernames, endpoints)</li>
            <li>Sensitive info (passwords, access tokens, keys)</li>
        </ul>

        <p>Config should be <span class='keyword'>decoupled</span> from pod definition and <span class='keyword'>portable</span> across the cluster.</p>

        <aside class='notes'>
            <ul>
                <li>In addition to scheduling workload as containers and pods, we will typically also need to provide configuration info for our applications.</li>
                <li>We'd like to be able to define the config in a way that keeps it well separated from the definition of our pods, so that the same pods and deployments can be migrated across environments without changing their definition at all; we should be able to swap out modular configuration objects to completely capture changes in config.</li>
                <li>Also, these modular configuration objects need to be managed by our orchestrator so they can be as portable as our pods themselves, able to be provisioned anywhere in our cluster.</li>
            </ul>
        </aside>

    </section>

    <section class="no_bg">
        <h2>ConfigMaps</h2>

        <ul>
            <li>Collections of key/value pairs, or text files</li>
            <li>Provisioned to containers via env vars or volume mounts</li>
            <li>Appropriate for low/no security config</li>
        </ul>

        <aside class='notes'>
            <ul>
                <li>For any non-sensitive configuration information, a configMap satisfies our desires for decoupled, portable configuration.</li>
                <li>ConfigMaps can be defined as lists of key/value pairs, which can be used to populate environment variables in containers, or as lists of files which can be used to populate volume mounts.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Secrets</h2>

        <ul>
            <li>Defined and provisioned similarly to configMaps (env vars or volume mounts)</li>
            <li>Intended for secure info:
                <ul>
                    <li>Provisioned in a tmpfs, never written to disk</li>
                </ul>
            </li>
            <li><span class='keyword'>Warning</span>: secrets are recoverable with <code>kubectl get secrets</code> from masters, and potentially with <code>docker container inspect</code> from host workers</li>
        </ul>

        <aside class='notes'>
            <ul>
                <li>For config that requires higher security guarantees, Kubernetes provides a construct parallel to configMaps called secrets.</li>
                <li>Secrets are used similarly to configMaps, in that they are defined separately from pods, and can populate environment variables and mounted files in a running container. Secrets are not, however, written to disk, and are deleted from the tmpfs they are stored in on worker nodes once the container consuming them is deleted.</li>
                <li>Furthermore, UCP sets up default Kube secret encryption on install via the aescbc provider discussed at <a href="https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/"></a>this site.</li>
                <li>Be aware that anyone with `kubectl get secrets` permissions on your cluster can recover the value of a secret from a master. Secrets can also be exposed via environment variables visible through `docker container inspect` on nodes hosting pods that consume a secret as an environment variable. Therefore, while secrets improve the security posture of sensitive information, proper RBAC and limited access to cluster nodes is still crucial for security.</li>
            </ul>
        </aside>
    </section>   
    
    <section class="no_bg">
        <h2>Further Reading</h2>
        <ul>
            <li>Docker &amp; Kubernetes: <a href="https://www.docker.com/kubernetes">https://www.docker.com/kubernetes</a></li>
            <li>Official Kubernetes Docs: <a href="https://kubernetes.io/docs">https://kubernetes.io/docs</a></li>
            <li>Tutorials: <a href="http://bit.ly/2yLGn61">http://bit.ly/2yLGn61</a></li>
            <li>Interactive Tutorials: <a href="https://bit.ly/2rdwIVZ">https://bit.ly/2rdwIVZ</a></li>
            <li>Understanding Kubernetes Networking: <a href="http://bit.ly/2kdI1qQ">http://bit.ly/2kdI1qQ</a></li>
            <li>Kubernetes the Hard Way: <a href="http://bit.ly/29Dq4wC">http://bit.ly/29Dq4wC</a></li>
        </ul>
        <aside class='notes'>
            <ul>
                <li>Additional resources about Kubernetes</li>
            </ul>
        </aside>
    </section>
</section>
<section>
    <section class="no_bg">
        <h2>Volumes</h2>
    </section>

    <section class="no_bg">
        <h2>Storage Volumes</h2>

        <ul>
            <li>Volumes: same lifecycle as pod (compare to persistent Docker volumes)</li>
            <li>PersistentVolumes: 'immortal' volume (similar to Docker)</li>
            <li>Storage backends exposed by <span class='keyword'>container storage interface</span> drivers</li>
        </ul>

        <aside class='notes'>
            <ul>
                <li>Similar to Docker containers, we often want storage for our applications that outlives the containers that isolate our processes; for this we have Kube volumes.</li>
                <li>One critical difference between Kube and Docker's volume solutions is that Kube volumes are created alongside pods, and do not outlive those pods; once a pod is deleted, the volumes it created are also destroyed. Compare this to a Docker volume, which is created independently from a container and by default outlives any container that mounts it.</li>
                <li>If we want a more 'Docker-like' persistent storage solution, PersistentVolumes provide volumes that are provisioned separately from pods, and persist past the lifecycle of any pods that mount them.</li>
                <li>Kubernetes abstracts away arbitrary third-party storage solutions using the Container Storage Interface, a generic standard for orchestrator storage drivers.</li>
            </ul>
        </aside>

    </section>

    <section data-background="#00a2a1" class="green_bg">
        <h2><img src="src/modules/Training-for-Kubernetes/08-storage/images/icon_task.png" class="moby_icon" alt="icon"> Exercise: Configuration, Secrets & Volumes</h2>
        
        <p>Work through</p>

        <ul>
            <li class='exercise' script='provisioning-kube-config.md'>Provisioning Kube Config</li>
        </ul>

        <p>in the Exercises book.</p>
        <h2 class="timer"></h2>

    </section>

    <section class="no_bg">
        <h2>Further Reading</h2>
        <ul>
            <li>Docker &amp; Kubernetes: <a href="https://www.docker.com/kubernetes">https://www.docker.com/kubernetes</a></li>
            <li>Official Kubernetes Docs: <a href="https://kubernetes.io/docs">https://kubernetes.io/docs</a></li>
            <li>Tutorials: <a href="http://bit.ly/2yLGn61">http://bit.ly/2yLGn61</a></li>
            <li>Interactive Tutorials: <a href="https://bit.ly/2rdwIVZ">https://bit.ly/2rdwIVZ</a></li>
            <li>Understanding Kubernetes Networking: <a href="http://bit.ly/2kdI1qQ">http://bit.ly/2kdI1qQ</a></li>
            <li>Kubernetes the Hard Way: <a href="http://bit.ly/29Dq4wC">http://bit.ly/29Dq4wC</a></li>
        </ul>
        <aside class='notes'>
            <ul>
                <li>Additional resources about Kubernetes</li>
            </ul>
        </aside>
    </section>
</section>
<section>
    <section class="no_bg">
        <h2>Kubernetes Networking</h2>
    </section>

    <section class="no_bg">
        <h2>Kubernetes Network Model</h2>
        <img src="src/modules/Training-for-Kubernetes/09-networking/images/kube-networking.png" alt="Kube Networking">
        <p>Requirements</p>
        <ul>
            <li>Pod &lt;--&gt; Pod without NAT</li>
            <li>Node &lt;--&gt; Pod without NAT</li>
            <li>Pod's peers find it at the same IP it finds itself</li>
            <li>Creates a <span class='keyword'>flat network</span>, like VMs</li>
        </ul>
        <aside class="notes">
            <ul>
                <li>Kubernetes does not have a strict opinion on how networking between pods has to be implemented. It only requests the following 3 characteristics of a valid networking implementation:</li>
                <li>(1) All pods can communicate with all other pods without NAT</li>
                <li>(2) All nodes running pods can communicate with all pods (and vice-versa) without NAT</li>
                <li>(3) IP that a pod sees itself as is the same IP that other pods see it as</li>
                <li>In our sample we have two nodes on a subnet 172.10.0.0/16 and all pods are on subnet 10.1.0.0/16 while node1 has subnet 10.1.1.0/24 and node2 has 10.1.2.0/24 reserved for its respective pods.</li>
                <li>According to the requirements (1) pod A needs to be able to reach pod B, pod C and pod D without NAT. (2) Furthermore node 1 and 2 need to be able to reach all pods A to D. (3) Finally pod A sees its own IP as 10.1.1.2 and all other pods in the network see pod A with the same IP 10.1.1.2 and can reach it accordingly.</li>
                <li>To elaborate a bit on the 3rd point: processes running inside any container of pod A see their IP as 10.1.1.2.</li>
                <li>Kube's networking model is most distinct from the Docker native CNM in its priorities; Kubernetes wanted a networking model that most closely resembled a flat network of VMs. By demanding all containers sit on a flat network and can all reach each other, Kubernetes forgoes Docker's secure by default firewalling but makes it very simple to port an application previously distributed across networked VMs into a collection of pods that are nearly identical from a networking perspective. This is the other sense in which kubernetes prioritized its communication model over its security model.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Service</h2>
        <div class="row">
            <div class="col-6">
                <p>Problem:</p>
                <ul>
                    <li>Pods are mortal</li>
                    <li>Pods are never resurrected</li>
                    <li>Pod IP Addr cannot be relied on</li>
                </ul>
                <p>Solution:</p>
                <ul>
                    <li><span class"keyword">Service</span> defines: 
                        <ul>
                            <li>Logical set of Pods</li>
                            <li>Policy how to access them</li>
                        </ul> </li>
                </ul>
            </div>
            <div class="col-6">
                <img src="src/modules/Training-for-Kubernetes/09-networking/images/service.png" title="Service">
            </div>
        </div>
        <aside class="notes">
            <ul>
                <li>Just like service tasks managed by Swarm, pods managed by Kubernetes come and go, either from failures, scheduling decisions, updates, or scaling.</li>
                <li>We don't want our application logic to have to watch out for these potentially fast-changing operational details; we'd rather abstract away a pool of identical pods behind a stable endpoint, which is what a Kubernetes service provides.</li>
                <li>A kube service is a fully-fledged object in the Kubernetes API just like Pods, ReplicaSets, and Deployments. They provide stable IP addresses, and support TCP and UDP (TCP by default). They also perform simple randomized load-balancing across Pods, though more advanced load balancing algorithms may be supported in the future. This adds up to a situation where Pods can come and go, and the Service automatically updates and continues to provide that stable networking endpoint.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>ClusterIP Services</h2>

        <div class='row'>
            <div class='col-8'>
                <img src='src/modules/Training-for-Kubernetes/09-networking/images/clusterip.png'></img>
            </div>
            <div class='col-4'>
                <ul>
                    <li><span class='keyword'>Usecase:</span>
                        <ul>
                            <li>Cluster internal origin</li>
                            <li>Stateless destination</li>
                            <li>Similar to Swarm VIP</li>
                        </ul>
                    </li>
                </ul>
            </div>
        </div>

        <aside class='notes'>
            <ul>
                <li>The most basic Kubernetes service is the clusterIP service. Traffic sent to the service IP and port will get randomly load balanced across all matching pods, on the service's targetPort port.</li>
                <li>Note this is for cluster internal communications only; the service IP will only be reachable from other pods running on the same cluster.</li>
                <li>Also note, the random routing implies this is appropriate only for stateless destination pods.</li>
                <li>Finally, recall that UCP automatically deploys a kube DNS service - so the IP of your clusterIP services, like all services, can be resolved by a DNS lookup of the service name, again from within the originating pod.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>NodePort Services</h2>

        <div class='row'>
            <div class='col-8'>
                <img src='src/modules/Training-for-Kubernetes/09-networking/images/nodeport.png'></img>
            </div>
            <div class='col-4'>
                <ul>
                    <li><span class='keyword'>Usecase:</span>
                        <ul>
                            <li>Cluster external origin</li>
                            <li>Stateless destination</li>
                            <li>Similar to Swarm L4 mesh</li>
                        </ul>
                    </li>
                </ul>
            </div>
        </div>

        <aside class='notes'>
            <ul>
                <li>Building off of the clusterIP service is the nodePort service, intended for routing traffic from outside the cluster to your pods.</li>
                <li>nodePort services automatically create clusterIP services that work exactly as described above; the nodePort service itself listens on a randomly assigned port on every node in the cluster, and forwards traffic inbound there to the clusterIP service, which in turn hands it off to the matching pods as above.</li>
                <li>Note that nodePort services listen on EVERY host in the cluster, regardless of what pods are running where; therefore, inbound traffic doesn't need to be targeted at a specific node. Your external load balancer could in principle just fan traffic across the whole cluster on the port selected by your nodePort service, and the Kube services will handle the rest of the routing.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Kubernetes Label Selectors</h2>

        <img src="src/modules/Training-for-Kubernetes/09-networking/images/labelselector.png" title="label selector" style='width:70%'>

        <aside class='notes'>
            <ul>
                <li>Since a Kubernetes service is a completely independent object, how do we connect it to the pods it's supposed to route traffic to?</li>
                <li>We address this problem with kube label selectors. Pods bear a metadata -> labels key, beneath which can contain any arbitrary label and value; meanwhile, services bear a selector -> matchLabels key beneath which resides the same label and value combination.</li>
                <li>You already saw this in the exercises when you created replicaSets and deployments; the higher level objects were matched to pods in the exact same way. In the examples you declared the pods simultaneously with the orchestration objects, but any pod, even ones declared separately, with a matching label will get picked up and managed by the replicaSet, deployment or service.</li>
                <li>In order to restrict what objects match what other objects in this way, Kubernetes also offers namespacing functionality for objects; in this workshop we'll just put everything in the default namespace, but in practice you might consider running multiple versions of an app (say dev and staging) in different namespaces, so the dev services don't point at staging pods, or vice versa.</li>
            </ul>
        </aside>

    </section>

    <section class="no_bg">
        <h2>Network Policies</h2>
        <div class="row">
            <div class="col-7">
                <ul>
                    <li>Network policies <span class="keyword">control traffic</span></li>
                    <li>Traffic allowed by default</li>
                    <li>Traffic denied if network policy exist but no rule allows it</li>
                    <li>Independent <span class="keyword">ingress</span> &amp; <span class="keyword">egress</span> rules</li>
                </ul>
            </div>
            <div class="col-5">
                <div class="pre large">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ...
  namespace: ...
  ...
spec:
  <span class="red-bg">podSelector:</span> ...
  <span class="red-bg">ingress:</span>
  - ...
  - ...
  <span class="red-bg">egress:</span>
  - ...
  - ...</div>
            </div>
        </div>
        <aside class="notes">
            <ul>
                <li>Network policies control traffic from and to pods</li>
                <li>Kubernetes defines policies but ignores them silently IF no supporting network plugin is installed.</li>
                <li>Calico is such a network plugin that Docker includes "as batteries included" in UCP 3.0. Calico supports network policies and is commercially backed by Tigera.</li>
                <li>Policies work based on labels (on pods). In a policy we have label selectors that define which pods are affected by the policy</li>
                <li>An empty label selector means that ALL pods are included: matchLabels: {}</li>
                <li>In addition to which pods it applies to a policy also defines which direction of traffic is affected: ingress (inbound traffic; who can access the pod) or egress (outbound traffic; where can the pod connect to)</li>
                <li>On the slide we see the template of a network policy with the podSelector and the ingress and egress rules.</li>
                <li>Traffic is allowed unless there is a network policy selecting the pod</li>
                <li>Traffic is denied if there are policies selecting the pod but none of them have rules allowing it</li>
                <li>We can only write rules to ** allow ** traffic</li>
                <li>Traffic is allowed if there is at least one policy allowing it</li>
                <li>Policies can also restrict port numbers and protocols, e.g. 3456/tcp</li>
                <li>Policy rules are additive (logical OR)</li>
                <li>Multiple pod selectors are also additive (logical OR)</li>
                <li>Network policies are scoped to their namespace (the one they're deployed to)</li>
                <li>Network policies add minimal latency (less than 1 ms overhead): http://blog.kubernetes.io/2016/09/high-performance-network-policies-kubernetes.html</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Sample Network Policies</h2>
        <img src="src/modules/Training-for-Kubernetes/09-networking/images/network-policies.png" alt="Sample Network Policy">
        <aside class='notes'>
            <ul>
                <li>Here we see a sample network policy that allows some traffic while denying other. Only components from the backend tier can communicate with the DB tier but not e.g. frontend components</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Kubernetes Networking Planes</h2>

        <ul>
            <li>
                Management:
                <ul>
                    <li>Master to Master: etcd Raft</li>
                    <li>Master to Node: apiserver (TCP 6443) &lt;-&gt; kubelet (TCP 10250)</li>
                </ul>
            </li>
            <li>
                Data &amp; Control:
                <ul>
                    <li>BYO networking</li>
                    <li>See Cluster DNS, <a href='http://bit.ly/2DMmdyt'>http://bit.ly/2DMmdyt</a></li>
                </ul>
            </li>
        </ul>

        <aside class='notes'>
            <ul>
                <li>Like a Swarm, Kubernetes needs a management, control, and data plane to orchestrate fully distributed applications.</li>
                <li>Kube's management plane consists of two distinct parts: etcd replicas across masters maintain a Raft consensus, and masters' apiserver communicates with node's kubelet.</li>
                <li>Unlike Swarm, Kubernetes control and data planes are largely bring-your-own, with the details governed by networking solutions like calico, flannel or weave.</li>
                <li>Also see the Cluster DNS addon for Kubernetes; this will provision a DNS server that registers DNS names for Kubernetes services and pods based on their names and namespaces.</li>
            </ul>
        </aside>

    </section>

    <section class="no_bg">
        <h2>Calico</h2>

        <img src="src/modules/Training-for-Kubernetes/09-networking/images/calico-routing.png" alt="bgp / ip in ip">

        <aside class='notes'>
            <ul>
                <li>Every kubernetes network plugin implements L3 routing differently; here we illustrate Calico, since that's the one that ships with UCP by default.</li>
                <li>Calico assigns a /26 subnet to each node in the cluster (a node can get additional /26 subnets as they fill up - but a particular /26 will belong to exactly one host.)</li>
                <li>All pods on a host receive IPs in this /26 subnet allocated by the calico IPAM.</li>
                <li>Each pod's network namespace is connected to the host network namespace via a veth, just like in Docker.</li>
                <li>Calico amends the host's routing table to direct traffic bound for a local pod to the corresponding veth endpoint, named 'cali*'.</li>
                <li>Calico also runs a BGP server (BIRD) in an all-to-all mesh, updating the routing tables of all other nodes in the cluster with information about which subnets have been assigned to which nodes. Then, if any traffic is destined for a subnet not corresponding to the local node, the destination node's IP is inferred from the /26 subnet, and the packet is sent via IP-in-IP.</li>
                <li>In this sense, Calico is using BGP as its networking control plane (compare to gossip in Swarm), and IP in IP as its data plane (compare to VXLAN)</li>
                <li>In the case of very large clusters, the all-to-all BGP mesh can become unperformant. It's also possible to configure calico route reflectors to serve as the 'hub' in a hub-and-spoke control plane, where all nodes route outbound traffic to the route reflectors rather than directly to its destination, and the route reflectors then pass the traffic to its destination. This way, the control plane scales linearly in cluster size rather than like n*n, though at the cost of having a central hub for all intra-cluster communications (needs high bandwidth, potential point of failure).</li>
            </ul>
        </aside>

    </section>

    <section data-background="#00a2a1" class="green_bg">
        <h2><img src="src/modules/Training-for-Kubernetes/09-networking/images/icon_task.png" class="moby_icon" alt="icon"> Exercise: Kubernetes Networking</h2>

        <p>Work through</p> 
        <ul>
            <li class='exercise' script='kube-networking.md'>Kubernetes Networking</li>
        </ul>

        <p>In the Exercises book.</p>
        <h2 class="timer"></h2>

    </section> 
    
    <section class="no_bg">
        <h2>Kubernetes Takeaways</h2>
        <ul>
            <li>Kubernetes provides more flexibility in its orchestration objects at the cost of more config</li>
        </ul>
        <aside class='notes'>
            <ul>
                <li>The key strategic things to understand when thinking about kube are its modularity, and its communication model.</li>
                <li>Compared to Swarm, Kube is much more modular, providing a great deal of flexibility in scheduling decisions. However, as is generally true for most software, added flexibility often results in more complicated config.</li>
                <li>Also comparing to swarm, kube offers a potentially powerful communication model via the concept of pods and its globally reachable network model. If your app requires very chatty containers that need interprocess communication or colocation, pods are an excellent design decision offered by kubernetes.</li>
            </ul>
        </aside>
    </section>

    <section class="no_bg">
        <h2>Further Reading</h2>
        <ul>
            <li>Docker &amp; Kubernetes: <a href="https://www.docker.com/kubernetes">https://www.docker.com/kubernetes</a></li>
            <li>Official Kubernetes Docs: <a href="https://kubernetes.io/docs">https://kubernetes.io/docs</a></li>
            <li>Tutorials: <a href="http://bit.ly/2yLGn61">http://bit.ly/2yLGn61</a></li>
            <li>Interactive Tutorials: <a href="https://bit.ly/2rdwIVZ">https://bit.ly/2rdwIVZ</a></li>
            <li>Understanding Kubernetes Networking: <a href="http://bit.ly/2kdI1qQ">http://bit.ly/2kdI1qQ</a></li>
            <li>Kubernetes the Hard Way: <a href="http://bit.ly/29Dq4wC">http://bit.ly/29Dq4wC</a></li>
        </ul>
        <aside class='notes'>
            <ul>
                <li>Additional resources about Kubernetes</li>
            </ul>
        </aside>
    </section>
</section>
<section>
    <section class="no_bg">
        <h2>Kubernetes Ingress</h2>
    </section>

    <section class="no_bg">
        <h2>Further Reading</h2>
        <ul>
            <li>Docker &amp; Kubernetes: <a href="https://www.docker.com/kubernetes">https://www.docker.com/kubernetes</a></li>
            <li>Official Kubernetes Docs: <a href="https://kubernetes.io/docs">https://kubernetes.io/docs</a></li>
            <li>Tutorials: <a href="http://bit.ly/2yLGn61">http://bit.ly/2yLGn61</a></li>
            <li>Interactive Tutorials: <a href="https://bit.ly/2rdwIVZ">https://bit.ly/2rdwIVZ</a></li>
            <li>Understanding Kubernetes Networking: <a href="http://bit.ly/2kdI1qQ">http://bit.ly/2kdI1qQ</a></li>
            <li>Kubernetes the Hard Way: <a href="http://bit.ly/29Dq4wC">http://bit.ly/29Dq4wC</a></li>
        </ul>
        <aside class='notes'>
            <ul>
                <li>Additional resources about Kubernetes</li>
            </ul>
        </aside>
    </section>
</section>
<section>
        
    <section class="no_bg">
        <h2>Fundamental Orchestration Takeaways</h2>

        <ul>
            <li>Distributed Application Architecture orchestrates one or more containers across one or more nodes</li>
            <li>Orchestrators abstract away the differences between processes and between nodes</li>
            <li>Orchestrators enhance scalability and stability</li>
        </ul>

        <aside class='notes'>
            <ul>
                <li>We started out this workshop wanting to run any app, anywhere, because process migration is so integral to modern enterprise computing.</li>
                <li>By exploring the concequences of that idea, we came up with this notion of distributed application engineering, that underwrites things like microservices and devops, while enhancing portability, density and security of our apps.</li>
                <li>But when we started thinking in terms of orchestrated containers, we realized the added power and opportunity of shifting our thinking away from individual processes on individual machines, towards understanding our applications as scalable groups of processes (services) and scalable groups of nodes (swarms).</li>
                <li>The portability of containers allows us to schedule tasks in a way that erases the difference between machines in our datacenters, and the immutability and rapid deployment of containers allowed us to create the abstraction of services that are intrinsically more scalable and more robust than any individual process could ever be.</li>
            </ul>
        </aside>

    </section>

</section><section>
    <section class="no_bg">
        <h2>Wrap Up Kubernetes</h2>
    </section>
    <section class="no_bg">
        <h2>A</h2>
        <!--<img src='src/modules/Training-for-Kubernetes/12-wrapup-kubernetes/images/sonarqube.png' style='height: 400px' class="transparent"></img>-->
    </section>
    <section data-background="#00a2a1" class="green_bg">
        <h2>Exercise Instructions</h2>
        <ul>
            <li>A</li>
            <li>B</li>
            <li>C</li>
            <li>D</li>
            <li>E</li>
            <li><b>Hint</b>: use ABCDEF</li>
        </ul>
        <br>
        <br>
        <h2 class="timer"></h2>
        <aside class="notes">
            Sidenotes
        </aside>
    </section>
    
    <section class="no_bg">
        <h2>Solution</h2>
        <div class='pre' style="font-size:small;">YAML RESSOURCE</div>
    </section>
</section>
            </div>
        </div>

        <script>

            // Full list of configuration options available at:
            // https://github.com/hakimel/reveal.js#configuration
            Reveal.initialize({
                
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]

            });

        </script>

    </body>
</html>